import os
import time
import threading
import queue
import uuid
import sys
import csv  # [NEW] ìƒ˜í”Œ ë°ì´í„° ì½ê¸°ìš©
from dotenv import load_dotenv

# [LangChain & Neo4j]
from langchain_community.graphs import Neo4jGraph
from langchain_experimental.graph_transformers import LLMGraphTransformer
from langchain_community.chains.graph_qa.cypher import GraphCypherQAChain
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document

# [Custom Modules]
from ontology_manager import OntologyManager 
from ontology import GraphSchema
from scenario_generator import ScenarioGenerator
from hr_loader import HRDataManager
from utils import load_prompt_file
from data_factory import DataFactory
from llm_factory import get_chat_model

# [ì„¤ì •] í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# [1. LLM ì—°ê²° (Factory Pattern)]
try:
    llm = get_chat_model()
except Exception as e:
    print(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    sys.exit(1)

# [2. DB ì—°ê²°]
graph = Neo4jGraph(
    url=os.getenv("NEO4J_URI", "bolt://localhost:7687"),
    username=os.getenv("NEO4J_USERNAME", "neo4j"),
    password=os.getenv("NEO4J_PASSWORD", "password")
)

# [ë¹„ë™ê¸°] ë°ì´í„° ëŒ€ê¸°ì—´
data_queue = queue.Queue()

# [í”„ë¡¬í”„íŠ¸ ë° ìŠ¤í‚¤ë§ˆ ë¡œë“œ]
QA_PROMPT_TEXT = load_prompt_file("src/prompt_qa.md")

# [ë§¤ë‹ˆì € ì´ˆê¸°í™”]
hr_manager = HRDataManager(data_queue, graph)
data_factory = DataFactory() 
ontology_manager = OntologyManager(llm) # ë™ì  ìŠ¤í‚¤ë§ˆ ë§¤ë‹ˆì €

# ì´ˆê¸° í•™ìŠµ ì§€ì¹¨ ìƒì„± (OntologyManagerê°€ ê´€ë¦¬í•˜ëŠ” ìŠ¤í‚¤ë§ˆ ê¸°ë°˜)
INGESTION_INSTRUCTIONS = ontology_manager.get_instruction_string()


# ---------------------------------------------------------
# 1. [Worker] ììœ¨ ì˜¨í†¨ë¡œì§€ í•™ìŠµê¸°
# ---------------------------------------------------------
def ingestion_worker():
    print("ğŸ§  [Loupe] ììœ¨ í•™ìŠµ ì—”ì§„ ê°€ë™ (Dynamic Ontology ê¸°ë°˜)")
    
    # ì›Œì»¤ ì‹œì‘ ì‹œì ì˜ ìµœì‹  ìŠ¤í‚¤ë§ˆ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    current_allowed_nodes = list(ontology_manager.current_schema["nodes"].keys())
    print(f"   ğŸ“œ ì ìš©ëœ ìŠ¤í‚¤ë§ˆ: {', '.join(current_allowed_nodes)} ë“±.")

    transformer = LLMGraphTransformer(
        llm=llm,
        allowed_nodes=current_allowed_nodes, # ë™ì  ë¦¬ìŠ¤íŠ¸ ì£¼ì…
        allowed_relationships=[], 
        additional_instructions=INGESTION_INSTRUCTIONS # ìœ„ì—ì„œ ìƒì„±í•œ ì§€ì¹¨ ì£¼ì…
    )

    while True:
        try:
            source_type, text = data_queue.get()
            prefix = "  [ìë™]" if source_type == "AUTO_GEN" else "  [ì œë³´]"
            if source_type == "HR_DB": prefix = "  [HR]"
            
            print(f"\n{prefix} ìˆ˜ì‹ : '{text}' -> í•™ìŠµ ì‹œì‘...")
            
            documents = [Document(page_content=text)]
            graph_documents = transformer.convert_to_graph_documents(documents)
            
            if graph_documents:
                graph.add_graph_documents(graph_documents)
                
                # Evidence Node ìƒì„± ë¡œì§
                evidence_id = f"EV_{int(time.time())}_{str(uuid.uuid4())[:8]}"
                extracted_node_ids = [node.id for node in graph_documents[0].nodes]
                
                evidence_query = """
                MERGE (e:Evidence {id: $ev_id})
                SET e.text = $text, e.source = $source, e.timestamp = datetime()
                WITH e
                MATCH (n) WHERE n.id IN $node_ids
                MERGE (n)-[:MENTIONED_IN]->(e)
                """
                graph.query(evidence_query, params={
                    "ev_id": evidence_id, "text": text, 
                    "source": source_type, "node_ids": extracted_node_ids
                })
                print(f"  [ë°±ê·¸ë¼ìš´ë“œ] í•™ìŠµ ì™„ë£Œ (ë…¸ë“œ {len(extracted_node_ids)}ê°œ ì—°ê²°ë¨)")
            else:
                print(f"  [ë°±ê·¸ë¼ìš´ë“œ] ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨")
            
            data_queue.task_done()
        except Exception as e:
            print(f"  âŒ [ë°±ê·¸ë¼ìš´ë“œ ì˜¤ë¥˜] {e}")

threading.Thread(target=ingestion_worker, daemon=True).start()

# ---------------------------------------------------------
# 2. [Agent] QA Engine
# ---------------------------------------------------------
def ask_loupe(question):
    graph.refresh_schema()
    mapping_rules = GraphSchema.get_qa_mapping()
    
    CYPHER_GENERATION_TEMPLATE = f"""
    Task: Generate Cypher statement to query a graph database.
    [Schema]:
    {{schema}}
    {mapping_rules}
    [Instructions]:
    1. Use 'elementId()' or 'id' property.
    2. Try to return Evidence nodes.
    Question: {{question}}
    """
    
    cypher_prompt = PromptTemplate(input_variables=["schema", "question"], template=CYPHER_GENERATION_TEMPLATE)
    qa_prompt = PromptTemplate(input_variables=["context", "question"], template=QA_PROMPT_TEXT)

    try:
        chain = GraphCypherQAChain.from_llm(
            llm, graph=graph, verbose=True, allow_dangerous_requests=True,
            cypher_prompt=cypher_prompt, qa_prompt=qa_prompt
        )
        return chain.invoke(question)
    except Exception as e:
        return {"result": f"ì˜¤ë¥˜ ë°œìƒ: {e}"}

# ---------------------------------------------------------
# 3. [Logic] ê´€ê³„ ì§‘ê³„ ì—”ì§„
# ---------------------------------------------------------
def aggregate_relationships():
    print("ğŸ”„ [ì‹œìŠ¤í…œ] ì¸ë¬¼ ê°„ ìƒí˜¸ì‘ìš© ì ìˆ˜ë¥¼ ì§‘ê³„í•˜ì—¬ ê´€ê³„ ì§€ë„ë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤...")
    query = """
    MATCH (p1:Person)-[r:INTERACTED]->(p2:Person)
    WITH p1, p2, sum(r.score) AS total_score
    WHERE total_score IS NOT NULL
    MERGE (p1)-[rel:RELATIONSHIP]-(p2)
    SET rel.strength = total_score, rel.last_updated = datetime()
    RETURN count(rel) as updated_count
    """
    try:
        result = graph.query(query)
        count = result[0]['updated_count'] if result else 0
        print(f"   âœ… {count}ìŒì˜ ì¸ë¬¼ ê´€ê³„ ê°•ë„(strength)ê°€ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"   âš ï¸ ê´€ê³„ ì§‘ê³„ ì˜¤ë¥˜: {e}")

# ---------------------------------------------------------
# 4. [Main] ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
# ---------------------------------------------------------
if __name__ == "__main__":
    print("--- ğŸ”® Loupe v1.0: Full Integrated System ---")
    print(f"--- ğŸ¤– Engine: {os.getenv('LLM_PROVIDER', 'Unknown').upper()} / {os.getenv('LLM_MODEL')} ---")
    
    simulator = ScenarioGenerator(data_queue)
    sim_thread = None

    try:
        while True:
            sim_status = "ON ğŸŸ¢" if simulator.is_running else "OFF âšª"
            
            print(f"\n------------------------------------------------")
            print(f" [1] ìˆ˜ë™ ì œë³´   [2] ì§ˆë¬¸í•˜ê¸°   [3] ì‹œë®¬ë ˆì´í„° {sim_status}")
            print(f" [4] ë‡Œ ì´ˆê¸°í™”   [5] HR ë°ì´í„° ë¡œë“œ   [6] ê´€ê³„ ì ìˆ˜ ì§‘ê³„")
            print(f" [7] í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±(CSV)   [8] AI ì˜¨í†¨ë¡œì§€ ë°œê²¬(New)   [q] ì¢…ë£Œ")
            choice = input(" ì„ íƒ > ")
            
            if choice == '1':
                text = input("ì œë³´í•  ë‚´ìš©: ")
                if text.strip(): 
                    data_queue.put(("USER", text))
                    print("  ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            elif choice == '2':
                query = input("ì§ˆë¬¸: ")
                if query.strip():
                    print("ğŸ•µï¸ ë¶„ì„ ì¤‘...")
                    res = ask_loupe(query)
                    print(f"\nğŸ—£ï¸ ë‹µë³€:\n{res['result']}")
                
            elif choice == '3':
                if not simulator.is_running:
                    if not os.path.exists("dummy/actors.csv"):
                        print("âš ï¸ 'dummy/actors.csv'ê°€ ì—†ìŠµë‹ˆë‹¤. [7]ë²ˆì„ ëˆŒëŸ¬ ë°ì´í„°ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
                    else:
                        sim_thread = threading.Thread(target=simulator.run, daemon=True)
                        sim_thread.start()
                else:
                    simulator.stop()
                    if sim_thread: sim_thread.join()

            elif choice == '4':
                if input("âš ï¸ ì •ë§ ì´ˆê¸°í™”í•©ë‹ˆê¹Œ? (y/n): ") == 'y':
                    try:
                        graph.query("MATCH (n) DETACH DELETE n")
                        print("ğŸ’¥ ì´ˆê¸°í™” ì™„ë£Œ")
                    except Exception as e:
                        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

            elif choice == '5':
                if not os.path.exists("dummy/hr_data.csv"):
                    print("âš ï¸ 'dummy/hr_data.csv'ê°€ ì—†ìŠµë‹ˆë‹¤. [7]ë²ˆì„ ëˆŒëŸ¬ ë°ì´í„°ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
                else:
                    hr_manager.load_csv("dummy/hr_data.csv")
                    # HR ë¡œë“œ í›„ ì¦‰ì‹œ ê´€ê³„ ì¶”ë¡  ì‹¤í–‰
                    hr_manager.run_relationship_inference()

            elif choice == '6':
                aggregate_relationships()
                
            elif choice == '7':
                data_factory.generate_all_data()

            elif choice == '8':
                # [NEW] ì˜¨í†¨ë¡œì§€ ìë™ ë°œê²¬ ë° ì§„í™”
                print("ğŸ•µï¸ ìµœê·¼ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìŠ¤í‚¤ë§ˆ í™•ì¥ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                samples = []
                if os.path.exists("dummy/actions.csv"):
                     with open("dummy/actions.csv", 'r', encoding='utf-8-sig') as f:
                        reader = csv.DictReader(f)
                        # ìƒ˜í”Œ 5ê°œë§Œ ì¶”ì¶œ
                        for i, row in enumerate(reader):
                            if i >= 5: break
                            samples.append(f"ì¥ì†Œ {row['location']}ì—ì„œ {row['target_group']} ê·¸ë£¹ì´ '{row['action']}' í–‰ë™ì„ í•¨.")
                
                if samples:
                    suggestion = ontology_manager.discover_schema(samples)
                    if suggestion:
                        print("\nğŸ¤– AIê°€ ì œì•ˆí•œ ìŠ¤í‚¤ë§ˆ ë³€ê²½ì•ˆ:")
                        print(suggestion)
                        if input("âœ¨ ì´ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ") == 'y':
                            ontology_manager.update_schema(suggestion)
                            print("âš ï¸ ì£¼ì˜: ë³€ê²½ëœ ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•˜ë ¤ë©´ í”„ë¡œê·¸ë¨ì„ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.")
                    else:
                        print("â„¹ï¸ í˜„ì¬ ë°ì´í„°ë¡œëŠ” ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                else:
                    print("âš ï¸ ë¶„ì„í•  'dummy/actions.csv' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. [7]ë²ˆìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.")

            elif choice == 'q':
                if simulator.is_running: simulator.stop()
                print("ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                sys.exit(0)
                
    except KeyboardInterrupt:
        if simulator.is_running: simulator.stop()
        print("\nê°•ì œ ì¢…ë£Œ")
        sys.exit(0)