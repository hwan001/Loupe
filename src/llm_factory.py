import os
from dotenv import load_dotenv

try:
    from langchain_openai import ChatOpenAI
except ImportError:
    ChatOpenAI = None

try:
    from langchain_google_genai import ChatGoogleGenerativeAI
except ImportError:
    ChatGoogleGenerativeAI = None

load_dotenv()

def get_chat_model():
    """
    í™˜ê²½ ë³€ìˆ˜(LLM_PROVIDER)ì— ë”°ë¼ ì ì ˆí•œ LangChain ChatModel ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    provider = os.getenv("LLM_PROVIDER", "openai").lower()  # ê¸°ë³¸ê°’ openai
    model_name = os.getenv("LLM_MODEL", "gpt-4o")
    temp = float(os.getenv("LLM_TEMPERATURE", "0"))

    print(f"ğŸ”Œ [System] LLM ì—°ê²° ì‹œë„: Provider='{provider}', Model='{model_name}'")

    if provider == "openai":
        if not ChatOpenAI: raise ImportError("langchain-openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return ChatOpenAI(
            model_name=model_name,
            temperature=temp
        )

    elif provider == "google":
        if not ChatGoogleGenerativeAI: raise ImportError("langchain-google-genai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return ChatGoogleGenerativeAI(
            model=model_name,
            temperature=temp,
            convert_system_message_to_human=True
        )

    # (ì¶”ê°€ í™•ì¥ ê°€ëŠ¥: Anthropic, Ollama ë“±)
    
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM_PROVIDERì…ë‹ˆë‹¤: {provider}")